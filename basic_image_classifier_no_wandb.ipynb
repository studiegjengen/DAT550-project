{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ModelWrapper import ModelWrapper\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "data_dir = \"./data/data-large/data\"\n",
    "img_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wandb Sweep training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 images belonging to 2 classes.\n",
      "Found 3431 images belonging to 2 classes.\n",
      "Found 1587 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\henriks\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\nadam.py:78: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Nadam, self).__init__(name, **kwargs)\n",
      "c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\utils\\ModelWrapper.py:102: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  return self.model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 14/938 [..............................] - ETA: 5:57 - loss: 0.6922 - accuracy: 0.5246"
     ]
    }
   ],
   "source": [
    "\n",
    "config_defaults = {\n",
    "      'epochs': 20,\n",
    "      'batch_size': 32,\n",
    "      'learning_rate': 0.0001,\n",
    "      'optimizer': 'nadam',\n",
    "      'hidden_layer_size': 64,\n",
    "      'conv_layer_1_size': 16,\n",
    "      'conv_layer_2_size': 32,\n",
    "      'conv_layer_3_size': 64,\n",
    "      'dropout': 0.5,\n",
    "   }\n",
    "\n",
    "# # Config is a variable that holds and saves hyperparameters and inputs\n",
    "config = dotdict(config_defaults)\n",
    "\n",
    "# init wrapper\n",
    "model_wrapper = ModelWrapper(data_dir, img_size, config.batch_size)\n",
    "\n",
    "input_layers = [\n",
    "   layers.Conv2D(filters = config.conv_layer_1_size, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "   layers.MaxPooling2D(),\n",
    "   layers.Conv2D(filters = config.conv_layer_2_size, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "   layers.MaxPooling2D(),\n",
    "   layers.Conv2D(filters = config.conv_layer_3_size, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "   layers.MaxPooling2D(),\n",
    "   layers.Dropout(config.dropout) if config.dropout > 0 else None,\n",
    "   layers.Flatten(),\n",
    "   layers.Dense(config.hidden_layer_size, activation='relu'),\n",
    "   layers.Dense(units = 1, activation='sigmoid')\n",
    "]\n",
    "input_layers = [e for e in input_layers if e is not None]\n",
    "\n",
    "# create model\n",
    "model_wrapper.create_model(None, input_layers, config, use_wandb=False)\n",
    "\n",
    "# Define the optimizer\n",
    "if config.optimizer=='sgd':\n",
    "   optimizer = tf.keras.optimizers.SGD(lr=config.learning_rate) \n",
    "elif config.optimizer=='rmsprop':\n",
    "   optimizer = tf.keras.optimizers.RMSprop(lr=config.learning_rate,)\n",
    "elif config.optimizer=='adam':\n",
    "   optimizer = tf.keras.optimizers.Adam(lr=config.learning_rate,) \n",
    "elif config.optimizer=='nadam':\n",
    "   optimizer = tf.keras.optimizers.Nadam(lr=config.learning_rate,) \n",
    "\n",
    "# Compile the model\n",
    "model_wrapper.model.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train the model\n",
    "model_wrapper.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the bess model NB: edit namd and path\n",
    "loaded_model = wandb.restore('model-best.h5', run_path=\"dat550/deepfake-efficientnet/runs/29425ckm\")\n",
    "best_model = load_model(loaded_model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = ModelWrapper(data_dir, img_size, 32)\n",
    "model_wrapper.evaluate_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper.export_to_png()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6186f98b4107da167f8e04d2b53209365f80479d5668ca57b5633229f74e4af5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
