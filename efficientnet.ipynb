{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.applications.efficientnet import EfficientNetB7\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:nj5o9fnr) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04008054d28416c93068e9712c5906e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.642 MB of 5.642 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▅█▁</td></tr><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▃▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁</td></tr><tr><td>val_loss</td><td>▁▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.41667</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.38148</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>1.63466</td></tr><tr><td>val_accuracy</td><td>0.5</td></tr><tr><td>val_loss</td><td>4.7333</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fresh-eon-7</strong>: <a href=\"https://wandb.ai/dat550/deepfake-efficientnet/runs/nj5o9fnr\" target=\"_blank\">https://wandb.ai/dat550/deepfake-efficientnet/runs/nj5o9fnr</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220418_213639-nj5o9fnr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:nj5o9fnr). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.14 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/adneovrebo/projects/school/DAT550-project/wandb/run-20220418_214017-2uhfrb2c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-efficientnet/runs/2uhfrb2c\" target=\"_blank\">glorious-hill-8</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-efficientnet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_defaults = {\n",
    "    'epochs': 3,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.0001,\n",
    "    'dropout': 0.5,\n",
    "    'regularization': 0.0001,\n",
    "}\n",
    "wandb.init(config=config_defaults, project=\"deepfake-efficientnet\", entity=\"dat550\")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = config.batch_size\n",
    "img_size = 128\n",
    "data_dir = \"./data/tester\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255,    #rescale the tensor values to [0,1]\n",
    "    rotation_range = 10,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.1,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory = f\"{data_dir}/train\",\n",
    "    target_size = (img_size, img_size),\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode = \"binary\",\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255    #rescale the tensor values to [0,1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory = f\"{data_dir}/validation\",\n",
    "    target_size = (img_size, img_size),\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode = \"binary\",\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_net = EfficientNetB7(\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (img_size, img_size, 3),\n",
    "    include_top = False,\n",
    "    pooling = 'max',\n",
    "    drop_connect_rate=0.5\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(efficient_net)\n",
    "model.add(layers.Dense(units = 512, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(config.regularization), bias_regularizer=tf.keras.regularizers.L2(config.regularization)))\n",
    "model.add(layers.Dropout(config.dropout))\n",
    "model.add(layers.Dense(units = 128, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(config.regularization), bias_regularizer=tf.keras.regularizers.L2(config.regularization)))\n",
    "model.add(layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb7 (Functional)  (None, 2560)             64097687  \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 512)               1311232   \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,474,712\n",
      "Trainable params: 65,163,985\n",
      "Non-trainable params: 310,727\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(lr=config.learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = f'f{wandb.run.name}_model.h5'\n",
    "\n",
    "custom_callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'min',\n",
    "        patience = 5,\n",
    "        verbose = 1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath = model_file,\n",
    "        monitor = 'val_loss',\n",
    "        mode = 'min',\n",
    "        verbose = 1,\n",
    "        save_best_only = True\n",
    "    ),\n",
    "    WandbCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/w2phyck94cjgjk_b1_t74h5w0000gn/T/ipykernel_49690/4008429657.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_train_function.<locals>.train_function at 0x7fdb9ff385e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9066 - accuracy: 0.5833\n",
      "Epoch 1: val_loss improved from inf to 1.22427, saving model to fglorious-hill-8_model.h5\n",
      "1/1 [==============================] - 42s 42s/step - loss: 0.9066 - accuracy: 0.5833 - val_loss: 1.2243 - val_accuracy: 0.5000 - _timestamp: 1650310957.0000 - _runtime: 54.0000\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6623 - accuracy: 0.4167\n",
      "Epoch 2: val_loss improved from 1.22427 to 0.80566, saving model to fglorious-hill-8_model.h5\n",
      "1/1 [==============================] - 16s 16s/step - loss: 1.6623 - accuracy: 0.4167 - val_loss: 0.8057 - val_accuracy: 0.5000 - _timestamp: 1650310972.0000 - _runtime: 69.0000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1692 - accuracy: 0.5000\n",
      "Epoch 3: val_loss did not improve from 0.80566\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.1692 - accuracy: 0.5000 - val_loss: 1.4603 - val_accuracy: 0.5000 - _timestamp: 1650310980.0000 - _runtime: 77.0000\n",
      "{'loss': [0.9066199660301208, 1.6622676849365234, 1.1691819429397583], 'accuracy': [0.5833333134651184, 0.4166666567325592, 0.5], 'val_loss': [1.2242740392684937, 0.8056626319885254, 1.460307002067566], 'val_accuracy': [0.5, 0.5, 0.5], '_timestamp': [1650310957, 1650310972, 1650310980], '_runtime': [54, 69, 77]}\n"
     ]
    }
   ],
   "source": [
    "# Train network\n",
    "num_epochs = config.epochs\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = num_epochs,\n",
    "    steps_per_epoch = len(train_generator),\n",
    "    validation_data = val_generator,\n",
    "    validation_steps = len(val_generator),\n",
    "    callbacks = custom_callbacks\n",
    ")\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255    #rescale the tensor values to [0,1]\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory = f\"{data_dir}/test\",\n",
    "    classes=['REAL', 'FAKE'],\n",
    "    target_size = (img_size, img_size),\n",
    "    color_mode = \"rgb\",\n",
    "    class_mode = None,\n",
    "    batch_size = 1,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 6s 116ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REAL/abqwwspghj1.jpg</td>\n",
       "      <td>0.442409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REAL/abqwwspghj2.jpg</td>\n",
       "      <td>0.442409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REAL/abqwwspghj3.jpg</td>\n",
       "      <td>0.442415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REAL/abqwwspghj4.jpg</td>\n",
       "      <td>0.442492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REAL/abqwwspghj5.jpg</td>\n",
       "      <td>0.442335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>REAL/abqwwspghj6.jpg</td>\n",
       "      <td>0.442469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FAKE/abqwwspghj1.jpg</td>\n",
       "      <td>0.442409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FAKE/abqwwspghj2.jpg</td>\n",
       "      <td>0.442409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FAKE/abqwwspghj3.jpg</td>\n",
       "      <td>0.442415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FAKE/abqwwspghj4.jpg</td>\n",
       "      <td>0.442492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FAKE/abqwwspghj5.jpg</td>\n",
       "      <td>0.442335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FAKE/abqwwspghj6.jpg</td>\n",
       "      <td>0.442469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Filename  Prediction\n",
       "0   REAL/abqwwspghj1.jpg    0.442409\n",
       "1   REAL/abqwwspghj2.jpg    0.442409\n",
       "2   REAL/abqwwspghj3.jpg    0.442415\n",
       "3   REAL/abqwwspghj4.jpg    0.442492\n",
       "4   REAL/abqwwspghj5.jpg    0.442335\n",
       "5   REAL/abqwwspghj6.jpg    0.442469\n",
       "6   FAKE/abqwwspghj1.jpg    0.442409\n",
       "7   FAKE/abqwwspghj2.jpg    0.442409\n",
       "8   FAKE/abqwwspghj3.jpg    0.442415\n",
       "9   FAKE/abqwwspghj4.jpg    0.442492\n",
       "10  FAKE/abqwwspghj5.jpg    0.442335\n",
       "11  FAKE/abqwwspghj6.jpg    0.442469"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the saved model that is considered the best\n",
    "best_model = load_model(model_file)\n",
    "\n",
    "# Generate predictions\n",
    "test_generator.reset()\n",
    "\n",
    "preds = best_model.predict(\n",
    "    test_generator,\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "test_results = pd.DataFrame({\n",
    "    \"Filename\": test_generator.filenames,\n",
    "    \"Prediction\": preds.flatten()\n",
    "})\n",
    "\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round predictions to either 0 or 1\n",
    "test_results[\"Rounded\"] = test_results[\"Prediction\"].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[6, 6],\n",
       "        [0, 0]])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive_fake = test_results[(test_results['Filename'].str.startswith('FAKE')) & (test_results['Rounded'] == 0)].count()[0]\n",
    "false_positive_fake = test_results[(test_results['Filename'].str.startswith('REAL')) & (test_results['Rounded'] == 0)].count()[0]\n",
    "\n",
    "true_positive_real = test_results[(test_results['Filename'].str.startswith('REAL')) & (test_results['Rounded'] == 1)].count()[0]\n",
    "false_positive_real = test_results[(test_results['Filename'].str.startswith('FAKE')) & (test_results['Rounded'] == 1)].count()[0]\n",
    "\n",
    "np.matrix([\n",
    "    [true_positive_fake, false_positive_fake],\n",
    "    [false_positive_real, true_positive_real]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "wandb: ERROR Error while calling W&B API: Error 1040: Too many connections (<Response [500]>)\n",
      "wandb: ERROR Error while calling W&B API: Error 1040: Too many connections (<Response [500]>)\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "# Log the resultmatrix to wandb\n",
    "wandb.log({\n",
    "    'true_positive_fake': true_positive_fake,\n",
    "    'false_positive_fake': false_positive_fake,\n",
    "    'true_positive_real': true_positive_real,\n",
    "    'false_positive_real': false_positive_real\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
