{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.applications.efficientnet import EfficientNetB7\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from utils.ModelWrapper import ModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:nj5o9fnr) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04008054d28416c93068e9712c5906e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='5.642 MB of 5.642 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▅█▁</td></tr><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>loss</td><td>█▃▁</td></tr><tr><td>val_accuracy</td><td>▁▁▁</td></tr><tr><td>val_loss</td><td>▁▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.41667</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.38148</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>loss</td><td>1.63466</td></tr><tr><td>val_accuracy</td><td>0.5</td></tr><tr><td>val_loss</td><td>4.7333</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fresh-eon-7</strong>: <a href=\"https://wandb.ai/dat550/deepfake-efficientnet/runs/nj5o9fnr\" target=\"_blank\">https://wandb.ai/dat550/deepfake-efficientnet/runs/nj5o9fnr</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220418_213639-nj5o9fnr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:nj5o9fnr). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.14 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/adneovrebo/projects/school/DAT550-project/wandb/run-20220418_214017-2uhfrb2c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-efficientnet/runs/2uhfrb2c\" target=\"_blank\">glorious-hill-8</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-efficientnet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config_defaults = {\n",
    "    'epochs': 3,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.0001,\n",
    "    'dropout': 0.5,\n",
    "    'regularization': 0.0001,\n",
    "}\n",
    "wandb.init(config=config_defaults, project=\"deepfake-efficientnet\", entity=\"dat550\")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = config.batch_size\n",
    "img_size = 128\n",
    "data_dir = \"./data/tester\"\n",
    "\n",
    "model_wrapper = ModelWrapper(data_dir, img_size, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = f'f{wandb.run.name}_model.h5'\n",
    "\n",
    "efficient_net = EfficientNetB7(\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (img_size, img_size, 3),\n",
    "    include_top = False,\n",
    "    pooling = 'max',\n",
    "    drop_connect_rate=0.5\n",
    ")\n",
    "\n",
    "model_layers = [\n",
    "    efficient_net,\n",
    "    layers.Dense(units = 512, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(config.regularization), bias_regularizer=tf.keras.regularizers.L2(config.regularization)),\n",
    "    layers.Dropout(config.dropout),\n",
    "    layers.Dense(units = 128, activation = 'relu', kernel_regularizer=tf.keras.regularizers.L2(config.regularization), bias_regularizer=tf.keras.regularizers.L2(config.regularization)),\n",
    "    layers.Dense(units = 1, activation = 'sigmoid'),\n",
    "]\n",
    "model_wrapper.create_model(model_file, model_layers, config)\n",
    "model_wrapper.model.compile(optimizer = tf.keras.optimizers.Adam(lr=config.learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_wrapper.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/w2phyck94cjgjk_b1_t74h5w0000gn/T/ipykernel_49690/4008429657.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_train_function.<locals>.train_function at 0x7fdb9ff385e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9066 - accuracy: 0.5833\n",
      "Epoch 1: val_loss improved from inf to 1.22427, saving model to fglorious-hill-8_model.h5\n",
      "1/1 [==============================] - 42s 42s/step - loss: 0.9066 - accuracy: 0.5833 - val_loss: 1.2243 - val_accuracy: 0.5000 - _timestamp: 1650310957.0000 - _runtime: 54.0000\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6623 - accuracy: 0.4167\n",
      "Epoch 2: val_loss improved from 1.22427 to 0.80566, saving model to fglorious-hill-8_model.h5\n",
      "1/1 [==============================] - 16s 16s/step - loss: 1.6623 - accuracy: 0.4167 - val_loss: 0.8057 - val_accuracy: 0.5000 - _timestamp: 1650310972.0000 - _runtime: 69.0000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1692 - accuracy: 0.5000\n",
      "Epoch 3: val_loss did not improve from 0.80566\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.1692 - accuracy: 0.5000 - val_loss: 1.4603 - val_accuracy: 0.5000 - _timestamp: 1650310980.0000 - _runtime: 77.0000\n",
      "{'loss': [0.9066199660301208, 1.6622676849365234, 1.1691819429397583], 'accuracy': [0.5833333134651184, 0.4166666567325592, 0.5], 'val_loss': [1.2242740392684937, 0.8056626319885254, 1.460307002067566], 'val_accuracy': [0.5, 0.5, 0.5], '_timestamp': [1650310957, 1650310972, 1650310980], '_runtime': [54, 69, 77]}\n"
     ]
    }
   ],
   "source": [
    "# Train network\n",
    "history = model_wrapper.fit()\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 6s 116ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REAL/abqwwspghj1.jpg</td>\n",
       "      <td>0.442409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REAL/abqwwspghj2.jpg</td>\n",
       "      <td>0.442409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REAL/abqwwspghj3.jpg</td>\n",
       "      <td>0.442415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REAL/abqwwspghj4.jpg</td>\n",
       "      <td>0.442492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REAL/abqwwspghj5.jpg</td>\n",
       "      <td>0.442335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>REAL/abqwwspghj6.jpg</td>\n",
       "      <td>0.442469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FAKE/abqwwspghj1.jpg</td>\n",
       "      <td>0.442409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FAKE/abqwwspghj2.jpg</td>\n",
       "      <td>0.442409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FAKE/abqwwspghj3.jpg</td>\n",
       "      <td>0.442415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FAKE/abqwwspghj4.jpg</td>\n",
       "      <td>0.442492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FAKE/abqwwspghj5.jpg</td>\n",
       "      <td>0.442335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FAKE/abqwwspghj6.jpg</td>\n",
       "      <td>0.442469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Filename  Prediction\n",
       "0   REAL/abqwwspghj1.jpg    0.442409\n",
       "1   REAL/abqwwspghj2.jpg    0.442409\n",
       "2   REAL/abqwwspghj3.jpg    0.442415\n",
       "3   REAL/abqwwspghj4.jpg    0.442492\n",
       "4   REAL/abqwwspghj5.jpg    0.442335\n",
       "5   REAL/abqwwspghj6.jpg    0.442469\n",
       "6   FAKE/abqwwspghj1.jpg    0.442409\n",
       "7   FAKE/abqwwspghj2.jpg    0.442409\n",
       "8   FAKE/abqwwspghj3.jpg    0.442415\n",
       "9   FAKE/abqwwspghj4.jpg    0.442492\n",
       "10  FAKE/abqwwspghj5.jpg    0.442335\n",
       "11  FAKE/abqwwspghj6.jpg    0.442469"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the saved model that is considered the best\n",
    "best_model = load_model(model_file)\n",
    "model_wrapper.evaluate_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper.export_to_png()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6186f98b4107da167f8e04d2b53209365f80479d5668ca57b5633229f74e4af5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
