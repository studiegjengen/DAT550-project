{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full flow: preprocess, train and predict\n",
    "Full flow of all modules implemented. Change `modeltype` to test differens models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import preprocess_videos\n",
    "from utils.ModelWrapper import ModelWrapper, ModelType\n",
    "import tensorflow as tf\n",
    "from utils.predict import predict_multiple\n",
    "from utils.dot_dict import Dotdict\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init configuration\n",
    "Change the configuration here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_WANDB = True\n",
    "MODEL_TYPE = ModelType.CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train datasets\n",
      "\t Processing train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [03:06, 16.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test datasets\n",
      "\t Processing test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [03:07, 18.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# takes approx 6 min\n",
    "datasets = {\n",
    "    \"train\": [\"train\"], # Train dataset folders, now points to sample files\n",
    "    \"test\": [\"test\"], # Test dataset fodler, not points to sample files\n",
    "}\n",
    "\n",
    "# When processing full directories remove skip_sampling=True because we don't need 50/50 split in the example.\n",
    "preprocess_videos(datasets, save_dir=\"data\", video_dir=\"sample\", skip_sampling=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdat550\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/adneovrebo/projects/school/DAT550-project/wandb/run-20220514_140058-1u12xp1n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-efficientnet/runs/1u12xp1n\" target=\"_blank\">azure-oath-37</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-efficientnet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configs\n",
    "# config_defaults = {\n",
    "#     'epochs': 3,\n",
    "#     'batch_size': 32,\n",
    "#     'learning_rate': 0.0001,\n",
    "#     'dropout': 0.5,\n",
    "#     'regularization': 0.0001,\n",
    "# }\n",
    "\n",
    "config_defaults = {\n",
    "    'epochs': 1,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.0001,\n",
    "    'optimizer': 'adam',\n",
    "    'hidden_layer_size': 64,\n",
    "    'conv_layer_1_size': 16,\n",
    "    'conv_layer_2_size': 32,\n",
    "    'conv_layer_3_size': 64,\n",
    "    'dropout': 0.5,\n",
    "    \"use_augmentation\": True,\n",
    "}\n",
    "\n",
    "if USE_WANDB:\n",
    "    wandb.init(config=config_defaults, project=\"deepfake-efficientnet\", entity=\"dat550\")\n",
    "    config = wandb.config\n",
    "else:\n",
    "    config = Dotdict(config_defaults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 71 images belonging to 2 classes.\n",
      "Found 13 images belonging to 2 classes.\n",
      "Found 159 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-14 14:01:10.342086: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The data_type argument of wandb.keras.WandbCallback is deprecated and will be removed in a future release. Please use input_type instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Setting input_type = data_type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 128, 128, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1048640   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,072,289\n",
      "Trainable params: 1,072,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model_file = f'models/{MODEL_TYPE.name}/{wandb.run.name}_model.h5'\n",
    "\n",
    "# init wrapper\n",
    "model_wrapper = ModelWrapper(data_dir, img_size, config,model_file=model_file, modeltype=MODEL_TYPE, use_wandb=USE_WANDB)\n",
    "model_wrapper.model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_wrapper.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - ETA: 0s - loss: 0.6698 - accuracy: 0.5352\n",
      "Epoch 1: val_loss improved from inf to 0.69766, saving model to models/CNN/azure-oath-37_model.h5\n",
      "3/3 [==============================] - 3s 705ms/step - loss: 0.6698 - accuracy: 0.5352 - val_loss: 0.6977 - val_accuracy: 0.5385 - _timestamp: 1652529677.0000 - _runtime: 19.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff51178ac70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 1s 6ms/step\n",
      "self.test_generator.filenames:  159\n",
      "preds:  159\n",
      "conf_matrix: \n",
      " [[140  19]\n",
      " [  0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD4CAYAAADB0SsLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAIl0lEQVR4nO3abWyVZx3H8d9/liXMCWwInbSVVIY6tjpcAhp0GeoojIWh6NxGpslEERfUhc0Nx8PidIDEjBBdwCodmwGm0b2ATQcJiXbysEFUGA+aMYZrCyuEUdB1BKSXb5oGxukpB9be5Xe+n6Qv7us+J/e/ufLNffecRkpJADxdkvUAALoOgQPGCBwwRuCAMQIHjJV09QWmRR8+pr/ILNlbl/UIKFBUDo9c69zBAWMEDhgjcMAYgQPGCBwwRuCAMQIHjBE4YIzAAWMEDhgjcMAYgQPGCBwwRuCAMQIHjBE4YIzAAWMEDhgjcMAYgQPGCBwwRuCAMQIHjBE4YIzAAWMEDhgjcMAYgQPGCBwwRuCAMQIHjBE4YIzAAWMEDhgjcMAYgQPGCBwwRuCAMQIHjBE4YIzAAWMEDhgjcMAYgQPGCBwwRuCAMQIHjBE4YIzAAWMEDhgj8A58bdkTWtj0mua8svmsczfPmK6l6Zje3//K9rWvLl6oR1/9h2Zv26iKT17fnaMih4cfX6JRd3xLE759f/vaP/fu0x33zdaEaQ9o2iM/1X/fbslwwu5B4B3YtHyFfj5u0lnrV5SX6ZrqL+jwv99oX7vulmoNHDpEc4cO14qp39fkJYu6c1Tk8KUxN+lXP/nhGWuzF/1S939jstYs/ZnGjBqpZb9fk9F03YfAO7DnxY1qeevIWeu3L5qvZx+cI6XUvvaJieO1+elVkqTXX9qi3v36qs9Vpd02K842omqY+n7g8jPW9jUe0IiqayRJo26o0roNL2UxWrcq6ewFEfFxSRMllbUtNUpanVLa3ZWD9UTX3zZezY0H1Lh9xxnr/coG6Uh9Q/txc0Oj+pUN0rE3m7p7RORx9eAKrd+0VTePGqEX6jbrwKHDWY/U5fLewSPiIUnPSApJL7f9hKRVETEzz/umRsTWiNi6Syfey3kz06t3b417+AGtnvtY1qPgPM2bMU0rn1unSdNn6u133lGvkk7vbxe9zn7DKZKuTSmdPH0xIh6XtFPSglxvSinVSKqRpGnRJ+V6zcVmwJBK9a8crDnbNkiS+pWXadbfXtSCkZ9Tc+N+XVFR3v7afuVlam7cn9Wo6MBHKspUO2+WJOn1hv36y8t/z3iirtfZ3+CtkgblWP9Q27misX/HLj1YOkSzKqs0q7JKzQ2NeuyGG3Ws6aC2r/6TPv31uyRJlZ8aoeNHj/F43gMdbj4qSWptbdXSVc/qzlvHZDxR1+vsDn6fpPUR8aqk+ra1D0u6WtL0Lpwrc1NW1uqjoz+ryz/YX/Prd2vNI/O0sfY3OV+7449rdd34av14zzadaGnRU/fc283T4t1mzF+sLdt36cix/+imu7+j7959u1qOH9eKNeskSdWfGalJ1aOzHbIbREr5n6Aj4hJJI3Xmh2xbUkqnzuUCLo/oxWTJ3rqsR0CBonJ45Frv9FOGlFKrpLP/2wNAj8f34IAxAgeMEThgjMABYwQOGCNwwBiBA8YIHDBG4IAxAgeMEThgjMABYwQOGCNwwBiBA8YIHDBG4IAxAgeMEThgjMABYwQOGCNwwBiBA8YIHDBG4IAxAgeMEThgjMABYwQOGCNwwBiBA8YIHDBG4IAxAgeMEThgjMABYwQOGCNwwBiBA8YIHDBG4IAxAgeMEThgjMABYwQOGCNwwBiBA8YIHDAWKaWuvULL0S6+AABd1jdyLXMHB4wROGCMwAFjBA4YI3DAGIEDxggcMEbggDECB4wROGCMwAFjBA4YI3DAGIEDxggcMEbggDECB4wROGCMwAFjBA4YI3DAGIEDxggcMEbggDECB4wROGCMwAFjBA4YI3DAGIEDxggcMEbggDECB4wROGCMwAFjBA4YI3DAGIEDxggcMEbggDECB4wROGCMwAFjBA4YI3DAGIEDxggcMEbggDECB4wR+Hmo27BJY7/4FY25bZJqap/Kehycg2LdMwIv0KlTp/TogoX69S8W6/k//FbPvbBWe17bm/VYyKOY94zAC7R9x04NrihXRXmZLu3VS7eOrdb6P9dlPRbyKOY9I/ACNR08pKtKS9uPS0sHqunQoQwnQmeKec/OO/CIuCfPuakRsTUittbULj/fSwC4QCUX8N4fSXoy14mUUo2kGklSy9F0AdfocUoHDtCbTU3tx01NB1U6YECGE6Ezxbxnee/gEbG9g59XJJXme6+rqmuHad8b9apvbNSJkyf1/Np1+vzoG7MeC3kU8551dgcvlTRW0pF3rYekjV0yUQ9XUlKiuQ/9QN+893s61dqqL0+coKFDhmQ9FvIo5j2LlDp+go6IZZKeTCn9Nce5lSmlyZ1ewewRHeiRLusbuZbzBv6eIHCg63UQOF+TAcYIHDBG4IAxAgeMEThgjMABYwQOGCNwwBiBA8YIHDBG4IAxAgeMEThgjMABYwQOGCNwwBiBA8YIHDBG4IAxAgeMEThgjMABYwQOGCNwwBiBA8YIHDBG4IAxAgeMEThgjMABYwQOGCNwwBiBA8YIHDBG4IAxAgeMEThgjMABYwQOGCNwwBiBA8YIHDBG4IAxAgeMEThgjMABYwQOGCNwwBiBA8YipZT1DBetiJiaUqrJeg6cm2LcL+7gF2Zq1gOgIEW3XwQOGCNwwBiBX5ii+nvOQNHtFx+yAca4gwPGCBwwRuDnISLGRcS/ImJPRMzMeh7kFxG1EXEwInZkPUt3I/ACRcT7JD0h6RZJwyTdFRHDsp0KnVguaVzWQ2SBwAs3UtKelNLelNIJSc9ImpjxTMgjpVQn6a2s58gCgReuTFL9accNbWtAj0PggDECL1yjpIrTjsvb1oAeh8ALt0XS0IiojIhLJd0paXXGMwE5EXiBUkr/kzRd0lpJuyX9LqW0M9upkE9ErJK0SdLHIqIhIqZkPVN34V9VAWPcwQFjBA4YI3DAGIEDxggcMEbggDECB4z9H0v40x9IxGZ9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_to_eval = model_wrapper.model\n",
    "model_wrapper.evaluate_model(model_to_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "result = predict_multiple(\"./sample/test\", model_to_eval, frame_rate=1, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>prediction</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>real_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acifjvzvpm.mp4</td>\n",
       "      <td>0.671522</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>acxnxvbsxk.mp4</td>\n",
       "      <td>0.656769</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aagfhgtpmv.mp4</td>\n",
       "      <td>0.700379</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abqwwspghj.mp4</td>\n",
       "      <td>0.663209</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aczrgyricp.mp4</td>\n",
       "      <td>0.678341</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acxwigylke.mp4</td>\n",
       "      <td>0.641430</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abarnvbtwb.mp4</td>\n",
       "      <td>0.668619</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>acqfdwsrhi.mp4</td>\n",
       "      <td>0.621262</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       video_name  prediction predicted_class real_class\n",
       "0  acifjvzvpm.mp4    0.671522            FAKE       FAKE\n",
       "1  acxnxvbsxk.mp4    0.656769            FAKE       FAKE\n",
       "2  aagfhgtpmv.mp4    0.700379            FAKE       FAKE\n",
       "3  abqwwspghj.mp4    0.663209            FAKE       FAKE\n",
       "4  aczrgyricp.mp4    0.678341            FAKE       FAKE\n",
       "5  acxwigylke.mp4    0.641430            FAKE       FAKE\n",
       "6  abarnvbtwb.mp4    0.668619            FAKE       REAL\n",
       "7  acqfdwsrhi.mp4    0.621262            FAKE       FAKE"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6186f98b4107da167f8e04d2b53209365f80479d5668ca57b5633229f74e4af5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
