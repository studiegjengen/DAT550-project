{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ModelWrapper import ModelWrapper\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import load_model\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdat550\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220513_110432-bjwslvco</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/bjwslvco\" target=\"_blank\">clean-shape-9</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wandb stuff\n",
    "config_defaults = {\n",
    "    'epochs': 1,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 0.0001,\n",
    "    'dropout': 0.5,\n",
    "    'regularization': 0.0001,\n",
    "}\n",
    "wandb.init(config=config_defaults, project=\"deepfake-basic\", entity=\"dat550\")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 images belonging to 2 classes.\n",
      "Found 3431 images belonging to 2 classes.\n",
      "Found 1587 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Init modle wrapper\n",
    "data_dir = \"./data/data-large/data\"\n",
    "img_size = 128\n",
    "\n",
    "model_wrapper = ModelWrapper(data_dir, img_size, config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 128, 128, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2097280   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,120,993\n",
      "Trainable params: 2,120,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\henriks\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "classes = ['FAKE', 'REAL']\n",
    "model_file = f'models/basic_f{wandb.run.name}_model.h5'\n",
    "\n",
    "\n",
    "Layers = [\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(units = 1, activation = 'sigmoid')\n",
    "]\n",
    "\n",
    "model_wrapper.create_model(model_file, Layers, config)\n",
    "model_wrapper.model.compile(optimizer = tf.keras.optimizers.Adam(lr=config.learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_wrapper.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\utils\\ModelWrapper.py:97: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  return self.model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - ETA: 0s - loss: 0.6549 - accuracy: 0.6032\n",
      "Epoch 1: val_loss improved from inf to 0.62683, saving model to models\\basicfclean-shape-9_model.h5\n",
      "938/938 [==============================] - 335s 356ms/step - loss: 0.6549 - accuracy: 0.6032 - val_loss: 0.6268 - val_accuracy: 0.6374 - _timestamp: 1652433021.0000 - _runtime: 349.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25dc2a5de50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1587/1587 [==============================] - 9s 6ms/step\n",
      "self.test_generator.filenames:  1587\n",
      "preds:  1587\n",
      "conf_matrix: \n",
      " [[411 429]\n",
      " [366 381]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_wrapper.evaluate_model(model_wrapper.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "model_wrapper.export_to_png()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6186f98b4107da167f8e04d2b53209365f80479d5668ca57b5633229f74e4af5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
