{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ModelWrapper import ModelWrapper\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdat550\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_003233-iwa4mv5e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/iwa4mv5e\" target=\"_blank\">devoted-moon-75</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/dat550/deepfake-basic/runs/iwa4mv5e?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1efa75b25b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init\n",
    "wandb_project_name = 'deepfake-basic'\n",
    "data_dir = \"./data/data-large/data\"\n",
    "img_size = 128\n",
    "wandb.init(project=wandb_project_name, entity=\"dat550\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wandb Sweep training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "   # Default values for hyper-parameters we're going to sweep over\n",
    "   config_defaults = {\n",
    "         'epochs': 15,\n",
    "         'batch_size': 32,\n",
    "         'learning_rate': 0.0001,\n",
    "         'optimizer': 'nadam',\n",
    "         'hidden_layer_size': 64,\n",
    "         'conv_layer_1_size': 16,\n",
    "         'conv_layer_2_size': 32,\n",
    "         'conv_layer_3_size': 64,\n",
    "         'dropout': 0.5,\n",
    "         \"use_augmentation\": True,\n",
    "      }\n",
    "   # Initialize wandb with a sample project name\n",
    "   wandb.init(config=config_defaults, project=wandb_project_name, entity=\"dat550\")\n",
    "\n",
    "   # # Config is a variable that holds and saves hyperparameters and inputs\n",
    "   config = wandb.config\n",
    "\n",
    "   # init wrapper\n",
    "   model_wrapper = ModelWrapper(data_dir, img_size, config.batch_size,  use_generator=False, sample_datasets=True)\n",
    "\n",
    "   data_augmentation = Sequential(\n",
    "      [\n",
    "         layers.RandomFlip(\"horizontal\", input_shape=(img_size, img_size, 3)),\n",
    "         layers.RandomRotation(0.1),\n",
    "         layers.RandomZoom(0.1),\n",
    "      ]\n",
    "   )\n",
    "\n",
    "   input_layers = [\n",
    "      data_augmentation if config.use_augmentation else None,\n",
    "      layers.Conv2D(filters = config.conv_layer_1_size, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(img_size, img_size, 3)),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(filters = config.conv_layer_2_size, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Conv2D(filters = config.conv_layer_3_size, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Dropout(config.dropout) if config.dropout > 0 else None,\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(config.hidden_layer_size, activation='relu'),\n",
    "      layers.Dense(units = 1, activation='sigmoid')\n",
    "   ]\n",
    "   input_layers = [e for e in input_layers if e is not None]\n",
    "\n",
    "   # create model\n",
    "   model_wrapper.create_model(None, input_layers, config)\n",
    "\n",
    "   # Define the optimizer\n",
    "   if config.optimizer=='sgd':\n",
    "      optimizer = tf.keras.optimizers.SGD(learning_rate=config.learning_rate) \n",
    "   elif config.optimizer=='rmsprop':\n",
    "      optimizer = tf.keras.optimizers.RMSprop(learning_rate=config.learning_rate,)\n",
    "   elif config.optimizer=='adam':\n",
    "      optimizer = tf.keras.optimizers.Adam(learning_rate=config.learning_rate,) \n",
    "   elif config.optimizer=='nadam':\n",
    "      optimizer = tf.keras.optimizers.Nadam(learning_rate=config.learning_rate,) \n",
    "   \n",
    "   # Compile the model\n",
    "   model_wrapper.model.compile(optimizer=optimizer,loss='binary_crossentropy', metrics=['accuracy'])\n",
    "   # Train the model\n",
    "   model_wrapper.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 05mt6dlf\n",
      "Sweep URL: https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gsoyhk76 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_003348-gsoyhk76</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/gsoyhk76\" target=\"_blank\">fragrant-sweep-1</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The data_type argument of wandb.keras.WandbCallback is deprecated and will be removed in a future release. Please use input_type instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Setting input_type = data_type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step- loss: 2.6251 - accuracy: 0.55\n",
      "118/118 [==============================] - 368s 3s/step - loss: 2.6251 - accuracy: 0.5517 - val_loss: 0.6613 - val_accuracy: 0.6027 - _timestamp: 1652481612.0000 - _runtime: 384.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41a59286e574dc2a37453093650bbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.763 MB of 17.155 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.04447…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.55172</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.66129</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.62507</td></tr><tr><td>val_accuracy</td><td>0.60274</td></tr><tr><td>val_loss</td><td>0.66129</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fragrant-sweep-1</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/gsoyhk76\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/gsoyhk76</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_003348-gsoyhk76\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0rvb2b2w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_004030-0rvb2b2w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/0rvb2b2w\" target=\"_blank\">proud-sweep-2</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 22ms/step- loss: 2.3268 - accuracy: 0.52\n",
      "118/118 [==============================] - 360s 3s/step - loss: 2.3268 - accuracy: 0.5239 - val_loss: 0.6857 - val_accuracy: 0.5249 - _timestamp: 1652482002.0000 - _runtime: 372.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56138fe33d5e4012b96268a027cbeec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.251 MB of 0.768 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.326976…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.52391</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.68566</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.3268</td></tr><tr><td>val_accuracy</td><td>0.52492</td></tr><tr><td>val_loss</td><td>0.68566</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">proud-sweep-2</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/0rvb2b2w\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/0rvb2b2w</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_004030-0rvb2b2w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v02g3551 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_004657-v02g3551</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/v02g3551\" target=\"_blank\">comic-sweep-3</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 20ms/step- loss: 394.1817 - accuracy: 0.53\n",
      "118/118 [==============================] - 424s 4s/step - loss: 394.1817 - accuracy: 0.5341 - val_loss: 0.6712 - val_accuracy: 0.5978 - _timestamp: 1652482461.0000 - _runtime: 443.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "400cd9ed99ae4853b3cedd8bb286e297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.562 MB of 33.508 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.01676…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.53415</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.6712</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>394.18173</td></tr><tr><td>val_accuracy</td><td>0.59778</td></tr><tr><td>val_loss</td><td>0.6712</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">comic-sweep-3</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/v02g3551\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/v02g3551</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_004657-v02g3551\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x91t4s69 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_005437-x91t4s69</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/x91t4s69\" target=\"_blank\">crisp-sweep-4</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 18ms/step- loss: 1.3472 - accuracy: 0.54\n",
      "235/235 [==============================] - 376s 2s/step - loss: 1.3472 - accuracy: 0.5404 - val_loss: 0.6577 - val_accuracy: 0.6051 - _timestamp: 1652482870.0000 - _runtime: 393.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444fbac4eea7456fac66cffc99ad91af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.639 MB of 25.360 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.02520…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.54042</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.65771</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.34716</td></tr><tr><td>val_accuracy</td><td>0.60507</td></tr><tr><td>val_loss</td><td>0.65771</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">crisp-sweep-4</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/x91t4s69\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/x91t4s69</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_005437-x91t4s69\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8jw6oxjo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_010128-8jw6oxjo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/8jw6oxjo\" target=\"_blank\">different-sweep-5</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "469/469 [==============================] - ETA: 0s - loss: 1.1414 - accuracy: 0.5884WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EFAB8891F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "469/469 [==============================] - 318s 675ms/step - loss: 1.1414 - accuracy: 0.5884 - val_loss: 0.6063 - val_accuracy: 0.6564 - _timestamp: 1652483226.0000 - _runtime: 338.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c638588b28412b898632db69096fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.720 MB of 0.838 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.858524…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.58844</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.60633</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.14143</td></tr><tr><td>val_accuracy</td><td>0.65637</td></tr><tr><td>val_loss</td><td>0.60633</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">different-sweep-5</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/8jw6oxjo\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/8jw6oxjo</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_010128-8jw6oxjo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f1gbxf6r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_010718-f1gbxf6r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/f1gbxf6r\" target=\"_blank\">fast-sweep-6</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "235/235 [==============================] - ETA: 0s - loss: 1.6386 - accuracy: 0.5098WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001EFAB7543A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "235/235 [==============================] - 490s 2s/step - loss: 1.6386 - accuracy: 0.5098 - val_loss: 0.6932 - val_accuracy: 0.5194 - _timestamp: 1652483740.0000 - _runtime: 502.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c788520ed3c94590ab0ee2041b4c3103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.464 MB of 0.790 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.587557…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5098</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.69324</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.63864</td></tr><tr><td>val_accuracy</td><td>0.51938</td></tr><tr><td>val_loss</td><td>0.69324</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fast-sweep-6</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/f1gbxf6r\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/f1gbxf6r</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_010718-f1gbxf6r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wkieqnqz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_011550-wkieqnqz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/wkieqnqz\" target=\"_blank\">devoted-sweep-7</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 15ms/step- loss: 1.3771 - accuracy: 0.50\n",
      "235/235 [==============================] - 486s 2s/step - loss: 1.3771 - accuracy: 0.5096 - val_loss: 0.6930 - val_accuracy: 0.5208 - _timestamp: 1652484250.0000 - _runtime: 500.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cd1620cbdb4a61843a06bc0c1f6ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.731 MB of 17.569 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.04163…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5096</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.69302</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.37707</td></tr><tr><td>val_accuracy</td><td>0.52084</td></tr><tr><td>val_loss</td><td>0.69302</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">devoted-sweep-7</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/wkieqnqz\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/wkieqnqz</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_011550-wkieqnqz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s3mqww2k with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_012418-s3mqww2k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/s3mqww2k\" target=\"_blank\">cool-sweep-8</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 14ms/step- loss: 2.7929 - accuracy: 0.61\n",
      "235/235 [==============================] - 362s 2s/step - loss: 2.7929 - accuracy: 0.6197 - val_loss: 0.6796 - val_accuracy: 0.6086 - _timestamp: 1652484633.0000 - _runtime: 375.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9364b8e88b48d7a175acdb5a6a0670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.572 MB of 0.790 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.724994…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.61975</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.67955</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.79292</td></tr><tr><td>val_accuracy</td><td>0.60857</td></tr><tr><td>val_loss</td><td>0.67955</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cool-sweep-8</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/s3mqww2k\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/s3mqww2k</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_012418-s3mqww2k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 42cozfeo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_013045-42cozfeo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/42cozfeo\" target=\"_blank\">polar-sweep-9</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 16ms/step- loss: 1.0934 - accuracy: 0.58\n",
      "235/235 [==============================] - 358s 2s/step - loss: 1.0934 - accuracy: 0.5839 - val_loss: 0.6295 - val_accuracy: 0.6231 - _timestamp: 1652485016.0000 - _runtime: 371.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09397eab1864cc2bb2827e7699f1ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.749 MB of 17.483 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.04282…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.58387</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.62945</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.0934</td></tr><tr><td>val_accuracy</td><td>0.62314</td></tr><tr><td>val_loss</td><td>0.62945</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">polar-sweep-9</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/42cozfeo\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/42cozfeo</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_013045-42cozfeo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1ywosjaq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_013706-1ywosjaq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/1ywosjaq\" target=\"_blank\">lunar-sweep-10</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 12ms/step- loss: 1.6235 - accuracy: 0.51\n",
      "469/469 [==============================] - 267s 567ms/step - loss: 1.6235 - accuracy: 0.5187 - val_loss: 0.6926 - val_accuracy: 0.5208 - _timestamp: 1652485307.0000 - _runtime: 280.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2a68133deb45be873a1aa15d991731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.511 MB of 0.802 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.638031…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.51874</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.69261</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.62351</td></tr><tr><td>val_accuracy</td><td>0.52084</td></tr><tr><td>val_loss</td><td>0.69261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lunar-sweep-10</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/1ywosjaq\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/1ywosjaq</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_013706-1ywosjaq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0wljm8uz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_014157-0wljm8uz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/0wljm8uz\" target=\"_blank\">wobbly-sweep-11</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 15ms/step- loss: 9.3601 - accuracy: 0.57\n",
      "118/118 [==============================] - 362s 3s/step - loss: 9.3601 - accuracy: 0.5740 - val_loss: 0.6552 - val_accuracy: 0.6261 - _timestamp: 1652485691.0000 - _runtime: 374.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c49c63789a43998c86ce834c22c176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.604 MB of 33.446 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.01805…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.57403</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.65521</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>9.36009</td></tr><tr><td>val_accuracy</td><td>0.62606</td></tr><tr><td>val_loss</td><td>0.65521</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wobbly-sweep-11</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/0wljm8uz\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/0wljm8uz</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_014157-0wljm8uz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kvs1cril with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_014823-kvs1cril</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/kvs1cril\" target=\"_blank\">decent-sweep-12</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 15ms/step- loss: 1.6268 - accuracy: 0.55\n",
      "235/235 [==============================] - 353s 1s/step - loss: 1.6268 - accuracy: 0.5562 - val_loss: 0.6796 - val_accuracy: 0.5873 - _timestamp: 1652486069.0000 - _runtime: 365.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc9f224fc1441418a5a8f62700a3a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.500 MB of 17.393 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.02875…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.55619</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.67963</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.62683</td></tr><tr><td>val_accuracy</td><td>0.58729</td></tr><tr><td>val_loss</td><td>0.67963</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">decent-sweep-12</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/kvs1cril\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/kvs1cril</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_014823-kvs1cril\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i6s067ma with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_015439-i6s067ma</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/i6s067ma\" target=\"_blank\">azure-sweep-13</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 21ms/step- loss: 1.2103 - accuracy: 0.54\n",
      "469/469 [==============================] - 520s 1s/step - loss: 1.2103 - accuracy: 0.5447 - val_loss: 0.6885 - val_accuracy: 0.5331 - _timestamp: 1652486611.0000 - _runtime: 532.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ba64b0fb4340199e85cf734624b212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.239 MB of 0.768 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.310998…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.54472</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.68847</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.21031</td></tr><tr><td>val_accuracy</td><td>0.53308</td></tr><tr><td>val_loss</td><td>0.68847</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">azure-sweep-13</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/i6s067ma\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/i6s067ma</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_015439-i6s067ma\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lhf88a0r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_020351-lhf88a0r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/lhf88a0r\" target=\"_blank\">iconic-sweep-14</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 30ms/step- loss: 5.5105 - accuracy: 0.53\n",
      "118/118 [==============================] - 567s 5s/step - loss: 5.5105 - accuracy: 0.5339 - val_loss: 0.8311 - val_accuracy: 0.5208 - _timestamp: 1652487210.0000 - _runtime: 579.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d80d763f4141a7961f8be88b348961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.794 MB of 17.558 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.04524…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.53395</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.83106</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>5.51049</td></tr><tr><td>val_accuracy</td><td>0.52084</td></tr><tr><td>val_loss</td><td>0.83106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">iconic-sweep-14</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/lhf88a0r\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/lhf88a0r</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_020351-lhf88a0r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: grhja6jx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_021338-grhja6jx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/grhja6jx\" target=\"_blank\">toasty-sweep-15</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 20ms/step- loss: 1.7934 - accuracy: 0.54\n",
      "235/235 [==============================] - 446s 2s/step - loss: 1.7934 - accuracy: 0.5419 - val_loss: 0.6587 - val_accuracy: 0.5777 - _timestamp: 1652487676.0000 - _runtime: 457.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa9734c871e4365bc5713938c118db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.131 MB of 33.549 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.03369…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.54185</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.65871</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.79344</td></tr><tr><td>val_accuracy</td><td>0.57767</td></tr><tr><td>val_loss</td><td>0.65871</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">toasty-sweep-15</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/grhja6jx\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/grhja6jx</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_021338-grhja6jx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7jtn0hok with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_022128-7jtn0hok</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/7jtn0hok\" target=\"_blank\">fanciful-sweep-16</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 21ms/step- loss: 2.4704 - accuracy: 0.61\n",
      "235/235 [==============================] - 439s 2s/step - loss: 2.4704 - accuracy: 0.6195 - val_loss: 0.6045 - val_accuracy: 0.6765 - _timestamp: 1652488138.0000 - _runtime: 450.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a81530238fd47d2b31fbb356f91f851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.824 MB of 0.824 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.61951</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.60451</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.47038</td></tr><tr><td>val_accuracy</td><td>0.67648</td></tr><tr><td>val_loss</td><td>0.60451</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fanciful-sweep-16</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/7jtn0hok\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/7jtn0hok</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_022128-7jtn0hok\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6zjc5bz7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_022909-6zjc5bz7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/6zjc5bz7\" target=\"_blank\">apricot-sweep-17</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 25ms/step- loss: 1.9783 - accuracy: 0.56\n",
      "235/235 [==============================] - 387s 2s/step - loss: 1.9783 - accuracy: 0.5615 - val_loss: 0.6226 - val_accuracy: 0.6462 - _timestamp: 1652488548.0000 - _runtime: 399.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506f68895fe7430dac40204cced9661d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.459 MB of 33.463 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.01371…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.56149</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.6226</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.97834</td></tr><tr><td>val_accuracy</td><td>0.64617</td></tr><tr><td>val_loss</td><td>0.6226</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">apricot-sweep-17</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/6zjc5bz7\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/6zjc5bz7</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_022909-6zjc5bz7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: czh7iurs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_023601-czh7iurs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/czh7iurs\" target=\"_blank\">snowy-sweep-18</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 13ms/step- loss: 2.9401 - accuracy: 0.51\n",
      "235/235 [==============================] - 350s 1s/step - loss: 2.9401 - accuracy: 0.5175 - val_loss: 0.6733 - val_accuracy: 0.5214 - _timestamp: 1652488922.0000 - _runtime: 361.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b02c7dae1474e20bc2990eb8afd4e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.657 MB of 0.795 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.826920…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.51747</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.67327</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.94008</td></tr><tr><td>val_accuracy</td><td>0.52142</td></tr><tr><td>val_loss</td><td>0.67327</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">snowy-sweep-18</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/czh7iurs\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/czh7iurs</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_023601-czh7iurs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b94ubziv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_024214-b94ubziv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/b94ubziv\" target=\"_blank\">true-sweep-19</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 17ms/step- loss: 4.1929 - accuracy: 0.52\n",
      "235/235 [==============================] - 358s 2s/step - loss: 4.1929 - accuracy: 0.5266 - val_loss: 0.6907 - val_accuracy: 0.5340 - _timestamp: 1652489303.0000 - _runtime: 369.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4166660da8a24651b3ca08989c675915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.779 MB of 17.469 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.04459…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.52658</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.69074</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>4.19293</td></tr><tr><td>val_accuracy</td><td>0.53396</td></tr><tr><td>val_loss</td><td>0.69074</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-sweep-19</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/b94ubziv\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/b94ubziv</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_024214-b94ubziv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f5acbfqe with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_024841-f5acbfqe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/f5acbfqe\" target=\"_blank\">daily-sweep-20</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 19ms/step- loss: 16.7329 - accuracy: 0.55\n",
      "118/118 [==============================] - 362s 3s/step - loss: 16.7329 - accuracy: 0.5562 - val_loss: 0.9177 - val_accuracy: 0.4958 - _timestamp: 1652489696.0000 - _runtime: 375.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cb648e454a4fd6a7d0a38ccdb1ccdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.548 MB of 0.776 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.706239…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.55622</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.91766</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>16.73293</td></tr><tr><td>val_accuracy</td><td>0.49577</td></tr><tr><td>val_loss</td><td>0.91766</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">daily-sweep-20</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/f5acbfqe\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/f5acbfqe</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_024841-f5acbfqe\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aryinarv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_025506-aryinarv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/aryinarv\" target=\"_blank\">electric-sweep-21</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 26ms/step- loss: 24.6761 - accuracy: 0.51\n",
      "118/118 [==============================] - 331s 3s/step - loss: 24.6761 - accuracy: 0.5114 - val_loss: 0.6923 - val_accuracy: 0.5208 - _timestamp: 1652490050.0000 - _runtime: 343.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5857e32d49dd4c689614c4ba0fe0618a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.752 MB of 0.779 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.965088…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5114</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.69231</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>24.67605</td></tr><tr><td>val_accuracy</td><td>0.52084</td></tr><tr><td>val_loss</td><td>0.69231</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">electric-sweep-21</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/aryinarv\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/aryinarv</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_025506-aryinarv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xtadtaha with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_030100-xtadtaha</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/xtadtaha\" target=\"_blank\">dainty-sweep-22</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 14ms/step- loss: 2.2519 - accuracy: 0.54\n",
      "235/235 [==============================] - 287s 1s/step - loss: 2.2519 - accuracy: 0.5463 - val_loss: 0.7053 - val_accuracy: 0.6097 - _timestamp: 1652490359.0000 - _runtime: 299.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592335b344bd48e3b33e846618fe6712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.450 MB of 25.283 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.01781…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.54629</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.70533</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.25191</td></tr><tr><td>val_accuracy</td><td>0.60973</td></tr><tr><td>val_loss</td><td>0.70533</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">dainty-sweep-22</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/xtadtaha\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/xtadtaha</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_030100-xtadtaha\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 41puc5sx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_030611-41puc5sx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/41puc5sx\" target=\"_blank\">warm-sweep-23</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 12ms/step- loss: 0.7818 - accuracy: 0.62\n",
      "469/469 [==============================] - 218s 462ms/step - loss: 0.7818 - accuracy: 0.6273 - val_loss: 0.5774 - val_accuracy: 0.6858 - _timestamp: 1652490601.0000 - _runtime: 230.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76984c80642f49fda3db467032922f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.699 MB of 0.844 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.828354…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.62728</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.57736</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.78178</td></tr><tr><td>val_accuracy</td><td>0.68581</td></tr><tr><td>val_loss</td><td>0.57736</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">warm-sweep-23</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/41puc5sx\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/41puc5sx</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_030611-41puc5sx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p2pirlr2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_031011-p2pirlr2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/p2pirlr2\" target=\"_blank\">restful-sweep-24</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 18ms/step- loss: 1.4317 - accuracy: 0.52\n",
      "469/469 [==============================] - 276s 582ms/step - loss: 1.4317 - accuracy: 0.5228 - val_loss: 0.6646 - val_accuracy: 0.5675 - _timestamp: 1652490901.0000 - _runtime: 289.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64783b9af8d49b99d73d422d9de006d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.409 MB of 0.788 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.518654…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.52281</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.66464</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.43171</td></tr><tr><td>val_accuracy</td><td>0.56747</td></tr><tr><td>val_loss</td><td>0.66464</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">restful-sweep-24</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/p2pirlr2\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/p2pirlr2</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_031011-p2pirlr2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 73z0anaa with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_031519-73z0anaa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/73z0anaa\" target=\"_blank\">hopeful-sweep-25</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 19ms/step- loss: 1108.9969 - accuracy: 0.51\n",
      "235/235 [==============================] - 452s 2s/step - loss: 1108.9969 - accuracy: 0.5180 - val_loss: 0.6925 - val_accuracy: 0.5208 - _timestamp: 1652491384.0000 - _runtime: 465.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92366bbdc3d147bf984df363ba7b7338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.786 MB of 17.194 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.04570…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.51797</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.69252</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1108.99695</td></tr><tr><td>val_accuracy</td><td>0.52084</td></tr><tr><td>val_loss</td><td>0.69252</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hopeful-sweep-25</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/73z0anaa\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/73z0anaa</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_031519-73z0anaa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4gbdkp79 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_032315-4gbdkp79</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/4gbdkp79\" target=\"_blank\">tough-sweep-26</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 16ms/step- loss: 2.5428 - accuracy: 0.52\n",
      "118/118 [==============================] - 348s 3s/step - loss: 2.5428 - accuracy: 0.5230 - val_loss: 0.6930 - val_accuracy: 0.5208 - _timestamp: 1652491754.0000 - _runtime: 359.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b5428c72f649a9a89bd6b5f0d1100e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.564 MB of 0.790 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.714177…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.52301</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.69299</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.54284</td></tr><tr><td>val_accuracy</td><td>0.52084</td></tr><tr><td>val_loss</td><td>0.69299</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">tough-sweep-26</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/4gbdkp79\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/4gbdkp79</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_032315-4gbdkp79\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z3bl0a2t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_032924-z3bl0a2t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/z3bl0a2t\" target=\"_blank\">stilted-sweep-27</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 20ms/step- loss: 1.9327 - accuracy: 0.51\n",
      "118/118 [==============================] - 364s 3s/step - loss: 1.9327 - accuracy: 0.5184 - val_loss: 0.6930 - val_accuracy: 0.5208 - _timestamp: 1652492141.0000 - _runtime: 377.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9996e810d424499dae8f87544f3bf6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.422 MB of 25.303 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.01666…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.51837</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.69301</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.93274</td></tr><tr><td>val_accuracy</td><td>0.52084</td></tr><tr><td>val_loss</td><td>0.69301</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">stilted-sweep-27</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/z3bl0a2t\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/z3bl0a2t</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_032924-z3bl0a2t\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2w1maqgy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_033555-2w1maqgy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/2w1maqgy\" target=\"_blank\">sparkling-sweep-28</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 19ms/step- loss: 1.5384 - accuracy: 0.55\n",
      "235/235 [==============================] - 461s 2s/step - loss: 1.5384 - accuracy: 0.5516 - val_loss: 0.6874 - val_accuracy: 0.6185 - _timestamp: 1652492628.0000 - _runtime: 473.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9880a42b7f44079ceba00480e2af2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 0.821 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.003387…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.55155</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.68738</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.53843</td></tr><tr><td>val_accuracy</td><td>0.61848</td></tr><tr><td>val_loss</td><td>0.68738</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sparkling-sweep-28</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/2w1maqgy\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/2w1maqgy</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_033555-2w1maqgy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dnzeyegb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_034359-dnzeyegb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/dnzeyegb\" target=\"_blank\">toasty-sweep-29</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 20ms/step- loss: nan - accuracy: 0.48\n",
      "235/235 [==============================] - 430s 2s/step - loss: nan - accuracy: 0.4800 - val_loss: nan - val_accuracy: 0.4792 - _timestamp: 1652493084.0000 - _runtime: 445.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7612354629d4498fbb28c49cdfbb410d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.441 MB of 0.802 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.549764…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.47999</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>nan</td></tr><tr><td>val_accuracy</td><td>0.47916</td></tr><tr><td>val_loss</td><td>nan</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">toasty-sweep-29</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/dnzeyegb\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/dnzeyegb</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_034359-dnzeyegb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eiuzs3li with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_035132-eiuzs3li</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/eiuzs3li\" target=\"_blank\">true-sweep-30</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 21ms/step- loss: 1.1060 - accuracy: 0.51\n",
      "235/235 [==============================] - 440s 2s/step - loss: 1.1060 - accuracy: 0.5187 - val_loss: 0.6870 - val_accuracy: 0.5538 - _timestamp: 1652493544.0000 - _runtime: 452.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc154f8b2024a10b369c57458769e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.648 MB of 5.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.129435…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.51871</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.68698</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.10598</td></tr><tr><td>val_accuracy</td><td>0.55377</td></tr><tr><td>val_loss</td><td>0.68698</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">true-sweep-30</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/eiuzs3li\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/eiuzs3li</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_035132-eiuzs3li\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z2twxu20 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_035920-z2twxu20</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/z2twxu20\" target=\"_blank\">misunderstood-sweep-31</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 28ms/step- loss: 2.4479 - accuracy: 0.63\n",
      "469/469 [==============================] - 556s 1s/step - loss: 2.4479 - accuracy: 0.6314 - val_loss: 0.6117 - val_accuracy: 0.6634 - _timestamp: 1652494128.0000 - _runtime: 568.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6893140f5bdc46d09ba77ca8f2182afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.711 MB of 33.562 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.02117…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.63139</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.61171</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.44795</td></tr><tr><td>val_accuracy</td><td>0.66336</td></tr><tr><td>val_loss</td><td>0.61171</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">misunderstood-sweep-31</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/z2twxu20\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/z2twxu20</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_035920-z2twxu20\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a98uardn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_040858-a98uardn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/a98uardn\" target=\"_blank\">worthy-sweep-32</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 17ms/step- loss: 1.2299 - accuracy: 0.55\n",
      "235/235 [==============================] - 427s 2s/step - loss: 1.2299 - accuracy: 0.5577 - val_loss: 0.6631 - val_accuracy: 0.6007 - _timestamp: 1652494579.0000 - _runtime: 440.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6a1c26717b46a9922a0f874437a0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.883 MB of 9.203 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.095947…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.55766</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.66309</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.22989</td></tr><tr><td>val_accuracy</td><td>0.6007</td></tr><tr><td>val_loss</td><td>0.66309</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">worthy-sweep-32</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/a98uardn\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/a98uardn</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_040858-a98uardn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ziacmtj7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_041626-ziacmtj7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/ziacmtj7\" target=\"_blank\">ethereal-sweep-33</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 16ms/step- loss: 1.1709 - accuracy: 0.57\n",
      "235/235 [==============================] - 363s 2s/step - loss: 1.1709 - accuracy: 0.5747 - val_loss: 0.7001 - val_accuracy: 0.6007 - _timestamp: 1652494961.0000 - _runtime: 374.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae04b64a1c04394938a0126236706d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.728 MB of 0.771 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.944769…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.57466</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.70005</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.17095</td></tr><tr><td>val_accuracy</td><td>0.6007</td></tr><tr><td>val_loss</td><td>0.70005</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ethereal-sweep-33</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/ziacmtj7\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/ziacmtj7</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_041626-ziacmtj7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0374enwk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_042251-0374enwk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/0374enwk\" target=\"_blank\">vivid-sweep-34</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 16ms/step- loss: 2.7053 - accuracy: 0.56\n",
      "235/235 [==============================] - 517s 2s/step - loss: 2.7053 - accuracy: 0.5615 - val_loss: 0.7563 - val_accuracy: 0.5669 - _timestamp: 1652495501.0000 - _runtime: 530.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ee17f158af4fecab72998a01bedee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.521 MB of 0.828 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.629300…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.56152</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.75628</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.70535</td></tr><tr><td>val_accuracy</td><td>0.56689</td></tr><tr><td>val_loss</td><td>0.75628</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vivid-sweep-34</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/0374enwk\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/0374enwk</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_042251-0374enwk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i2o9ud2d with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_043152-i2o9ud2d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/i2o9ud2d\" target=\"_blank\">twilight-sweep-35</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 23ms/step- loss: 2.1087 - accuracy: 0.58\n",
      "235/235 [==============================] - 521s 2s/step - loss: 2.1087 - accuracy: 0.5804 - val_loss: 0.6402 - val_accuracy: 0.6319 - _timestamp: 1652496046.0000 - _runtime: 534.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88d2c71a14b4da49a6041dea0c29fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.638 MB of 17.487 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.03650…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.58037</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.64022</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.10868</td></tr><tr><td>val_accuracy</td><td>0.63189</td></tr><tr><td>val_loss</td><td>0.64022</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">twilight-sweep-35</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/i2o9ud2d\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/i2o9ud2d</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_043152-i2o9ud2d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n4ejbpd0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_044055-n4ejbpd0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/n4ejbpd0\" target=\"_blank\">wise-sweep-36</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 22ms/step- loss: 2.4068 - accuracy: 0.58\n",
      "235/235 [==============================] - 455s 2s/step - loss: 2.4068 - accuracy: 0.5854 - val_loss: 0.6260 - val_accuracy: 0.6543 - _timestamp: 1652496525.0000 - _runtime: 469.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9511e1c82547698c91ecde31a59028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.926 MB of 33.516 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.02762…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5854</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.62604</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.40683</td></tr><tr><td>val_accuracy</td><td>0.65433</td></tr><tr><td>val_loss</td><td>0.62604</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wise-sweep-36</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/n4ejbpd0\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/n4ejbpd0</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_044055-n4ejbpd0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e5e09f2u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_044904-e5e09f2u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/e5e09f2u\" target=\"_blank\">still-sweep-37</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 14ms/step- loss: 2.7826 - accuracy: 0.61\n",
      "235/235 [==============================] - 257s 1s/step - loss: 2.7826 - accuracy: 0.6181 - val_loss: 0.5699 - val_accuracy: 0.7013 - _timestamp: 1652496813.0000 - _runtime: 268.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82226e5bdfc64d56ab1f4f515fe60fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.757 MB of 17.127 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.04418…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.61811</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.56986</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.78257</td></tr><tr><td>val_accuracy</td><td>0.70125</td></tr><tr><td>val_loss</td><td>0.56986</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">still-sweep-37</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/e5e09f2u\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/e5e09f2u</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_044904-e5e09f2u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7n3xyad5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_045351-7n3xyad5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/7n3xyad5\" target=\"_blank\">comic-sweep-38</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 11ms/step- loss: 2.8836 - accuracy: 0.62\n",
      "235/235 [==============================] - 254s 1s/step - loss: 2.8836 - accuracy: 0.6280 - val_loss: 0.7242 - val_accuracy: 0.6441 - _timestamp: 1652497096.0000 - _runtime: 265.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a001ce6ceb460c8b4f9d496e2900fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.527 MB of 17.117 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.03077…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.62798</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.72421</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.88361</td></tr><tr><td>val_accuracy</td><td>0.64413</td></tr><tr><td>val_loss</td><td>0.72421</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">comic-sweep-38</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/7n3xyad5\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/7n3xyad5</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_045351-7n3xyad5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w3bk07ce with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_045826-w3bk07ce</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/w3bk07ce\" target=\"_blank\">fearless-sweep-39</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 12ms/step- loss: 3.8670 - accuracy: 0.53\n",
      "235/235 [==============================] - 294s 1s/step - loss: 3.8670 - accuracy: 0.5301 - val_loss: 0.6683 - val_accuracy: 0.6010 - _timestamp: 1652497413.0000 - _runtime: 306.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a41f0a2b9f542b7ae5855249d510e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='2.479 MB of 17.147 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.14459…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.53011</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.66832</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>3.86698</td></tr><tr><td>val_accuracy</td><td>0.60099</td></tr><tr><td>val_loss</td><td>0.66832</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fearless-sweep-39</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/w3bk07ce\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/w3bk07ce</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_045826-w3bk07ce\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 57wilwky with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_050343-57wilwky</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/57wilwky\" target=\"_blank\">sleek-sweep-40</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 13ms/step- loss: 3.7104 - accuracy: 0.54\n",
      "235/235 [==============================] - 341s 1s/step - loss: 3.7104 - accuracy: 0.5462 - val_loss: 0.6556 - val_accuracy: 0.6223 - _timestamp: 1652497776.0000 - _runtime: 353.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432e5f577a954323b1981541649e22a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.731 MB of 33.228 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.02198…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.54622</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.65562</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>3.71044</td></tr><tr><td>val_accuracy</td><td>0.62227</td></tr><tr><td>val_loss</td><td>0.65562</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sleek-sweep-40</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/57wilwky\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/57wilwky</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_050343-57wilwky\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ke66to6s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_050947-ke66to6s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/ke66to6s\" target=\"_blank\">vital-sweep-41</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 20ms/step- loss: 3.0854 - accuracy: 0.54\n",
      "118/118 [==============================] - 423s 4s/step - loss: 3.0854 - accuracy: 0.5441 - val_loss: 0.7500 - val_accuracy: 0.5774 - _timestamp: 1652498222.0000 - _runtime: 435.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c947539bc3d446a7a44aaab477b26095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.459 MB of 0.754 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.609445…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.54408</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.74997</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>3.08541</td></tr><tr><td>val_accuracy</td><td>0.57738</td></tr><tr><td>val_loss</td><td>0.74997</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vital-sweep-41</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/ke66to6s\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/ke66to6s</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_050947-ke66to6s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i4qew313 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_051720-i4qew313</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/i4qew313\" target=\"_blank\">resilient-sweep-42</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 16ms/step- loss: 1.0928 - accuracy: 0.63\n",
      "469/469 [==============================] - 338s 719ms/step - loss: 1.0928 - accuracy: 0.6307 - val_loss: 0.5776 - val_accuracy: 0.6832 - _timestamp: 1652498590.0000 - _runtime: 350.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dc1e4d2f9342f1be8cc185c50369ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.657 MB of 0.800 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.820613…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.63065</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.57759</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.09282</td></tr><tr><td>val_accuracy</td><td>0.68318</td></tr><tr><td>val_loss</td><td>0.57759</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">resilient-sweep-42</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/i4qew313\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/i4qew313</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_051720-i4qew313\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zvuf3k15 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_052319-zvuf3k15</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/zvuf3k15\" target=\"_blank\">misty-sweep-43</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 25ms/step- loss: 2.5933 - accuracy: 0.50\n",
      "235/235 [==============================] - 431s 2s/step - loss: 2.5933 - accuracy: 0.5056 - val_loss: 0.6930 - val_accuracy: 0.5208 - _timestamp: 1652499042.0000 - _runtime: 443.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924be84a4f514dafad9e19f89f9dce92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.621 MB of 17.189 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.03613…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.50557</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.69303</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.59333</td></tr><tr><td>val_accuracy</td><td>0.52084</td></tr><tr><td>val_loss</td><td>0.69303</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">misty-sweep-43</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/zvuf3k15\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/zvuf3k15</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_052319-zvuf3k15\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0c8sd0a4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_053053-0c8sd0a4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/0c8sd0a4\" target=\"_blank\">trim-sweep-44</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 29ms/step- loss: 4.3389 - accuracy: 0.56\n",
      "235/235 [==============================] - 613s 3s/step - loss: 4.3389 - accuracy: 0.5626 - val_loss: 0.6655 - val_accuracy: 0.6191 - _timestamp: 1652499679.0000 - _runtime: 626.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b183aa4b20db4edea26ec5cd6de70e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.158 MB of 33.555 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.00471…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.56256</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.66549</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>4.3389</td></tr><tr><td>val_accuracy</td><td>0.61906</td></tr><tr><td>val_loss</td><td>0.66549</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">trim-sweep-44</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/0c8sd0a4\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/0c8sd0a4</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_053053-0c8sd0a4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2iulxrwb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_054131-2iulxrwb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/2iulxrwb\" target=\"_blank\">giddy-sweep-45</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 26ms/step- loss: 2.1923 - accuracy: 0.58\n",
      "235/235 [==============================] - 555s 2s/step - loss: 2.1923 - accuracy: 0.5891 - val_loss: 0.6449 - val_accuracy: 0.6374 - _timestamp: 1652500258.0000 - _runtime: 567.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccce94defc7a410984235eb0dce57fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.805 MB of 0.805 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.58914</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.64494</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.1923</td></tr><tr><td>val_accuracy</td><td>0.63742</td></tr><tr><td>val_loss</td><td>0.64494</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">giddy-sweep-45</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/2iulxrwb\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/2iulxrwb</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_054131-2iulxrwb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rd4rloxp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_055111-rd4rloxp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/rd4rloxp\" target=\"_blank\">denim-sweep-46</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 17ms/step- loss: 6.7027 - accuracy: 0.55\n",
      "235/235 [==============================] - 497s 2s/step - loss: 6.7027 - accuracy: 0.5534 - val_loss: 0.9525 - val_accuracy: 0.5380 - _timestamp: 1652500780.0000 - _runtime: 509.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3966526d2c32417eb9dbfd299dc6eb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.888 MB of 33.565 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.02644…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.55335</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.95246</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>6.70265</td></tr><tr><td>val_accuracy</td><td>0.53804</td></tr><tr><td>val_loss</td><td>0.95246</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">denim-sweep-46</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/rd4rloxp\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/rd4rloxp</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_055111-rd4rloxp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bltje17e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_055953-bltje17e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/bltje17e\" target=\"_blank\">balmy-sweep-47</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 23ms/step- loss: 1.9611 - accuracy: 0.59\n",
      "235/235 [==============================] - 440s 2s/step - loss: 1.9611 - accuracy: 0.5906 - val_loss: 0.6714 - val_accuracy: 0.6135 - _timestamp: 1652501244.0000 - _runtime: 451.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1feb5d3b071d4efe81c85469a5bdf10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.572 MB of 0.785 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.729651…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5906</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.67141</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.96111</td></tr><tr><td>val_accuracy</td><td>0.61352</td></tr><tr><td>val_loss</td><td>0.67141</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">balmy-sweep-47</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/bltje17e\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/bltje17e</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_055953-bltje17e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kfhph1je with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_060742-kfhph1je</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/kfhph1je\" target=\"_blank\">sandy-sweep-48</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 19ms/step- loss: 2.6348 - accuracy: 0.58\n",
      "469/469 [==============================] - 509s 1s/step - loss: 2.6348 - accuracy: 0.5831 - val_loss: 0.6467 - val_accuracy: 0.6339 - _timestamp: 1652501784.0000 - _runtime: 522.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cef3ce4f5d247b8bc65a0848b4f6cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.560 MB of 33.547 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.01670…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.58307</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.64669</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.6348</td></tr><tr><td>val_accuracy</td><td>0.63393</td></tr><tr><td>val_loss</td><td>0.64669</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sandy-sweep-48</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/kfhph1je\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/kfhph1je</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_060742-kfhph1je\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uxlbvu0f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_061635-uxlbvu0f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/uxlbvu0f\" target=\"_blank\">vague-sweep-49</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 27ms/step- loss: 1.5627 - accuracy: 0.57\n",
      "235/235 [==============================] - 552s 2s/step - loss: 1.5627 - accuracy: 0.5719 - val_loss: 0.6321 - val_accuracy: 0.6468 - _timestamp: 1652502360.0000 - _runtime: 565.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e387b9b48b4324b73504160552489e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.799 MB of 17.561 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.04550…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.57193</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.63209</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.56269</td></tr><tr><td>val_accuracy</td><td>0.64675</td></tr><tr><td>val_loss</td><td>0.63209</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vague-sweep-49</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/uxlbvu0f\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/uxlbvu0f</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_061635-uxlbvu0f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5m0uveom with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_062610-5m0uveom</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/5m0uveom\" target=\"_blank\">sparkling-sweep-50</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 23ms/step- loss: 3.0112 - accuracy: 0.56\n",
      "235/235 [==============================] - 511s 2s/step - loss: 3.0112 - accuracy: 0.5622 - val_loss: 0.6811 - val_accuracy: 0.5762 - _timestamp: 1652502893.0000 - _runtime: 522.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26689fd0946a4b608d1ab7b8280bff3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.654 MB of 17.294 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.03783…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.56222</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.68111</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>3.01124</td></tr><tr><td>val_accuracy</td><td>0.57622</td></tr><tr><td>val_loss</td><td>0.68111</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">sparkling-sweep-50</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/5m0uveom\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/5m0uveom</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_062610-5m0uveom\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mkct3qy6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_063503-mkct3qy6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/mkct3qy6\" target=\"_blank\">vibrant-sweep-51</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 18ms/step- loss: 2.2706 - accuracy: 0.63\n",
      "469/469 [==============================] - 320s 678ms/step - loss: 2.2706 - accuracy: 0.6314 - val_loss: 0.5978 - val_accuracy: 0.6899 - _timestamp: 1652503238.0000 - _runtime: 335.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49b7f10f8974033ae856b642a2a6e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.479 MB of 0.810 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.591833…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.63142</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.59782</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.27062</td></tr><tr><td>val_accuracy</td><td>0.68989</td></tr><tr><td>val_loss</td><td>0.59782</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vibrant-sweep-51</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/mkct3qy6\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/mkct3qy6</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_063503-mkct3qy6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xpt2khh7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_064056-xpt2khh7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/xpt2khh7\" target=\"_blank\">glowing-sweep-52</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 29ms/step- loss: 0.9824 - accuracy: 0.52\n",
      "469/469 [==============================] - 507s 1s/step - loss: 0.9824 - accuracy: 0.5268 - val_loss: 0.6844 - val_accuracy: 0.5450 - _timestamp: 1652503775.0000 - _runtime: 519.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d1f6daed7143c5b33d7eba32a8bae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.568 MB of 0.791 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.717422…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.52678</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.68438</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.9824</td></tr><tr><td>val_accuracy</td><td>0.54503</td></tr><tr><td>val_loss</td><td>0.68438</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glowing-sweep-52</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/xpt2khh7\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/xpt2khh7</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_064056-xpt2khh7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tohxipq2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_064947-tohxipq2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/tohxipq2\" target=\"_blank\">drawn-sweep-53</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 16ms/step- loss: 2.7101 - accuracy: 0.62\n",
      "469/469 [==============================] - 373s 792ms/step - loss: 2.7101 - accuracy: 0.6279 - val_loss: 0.5976 - val_accuracy: 0.6674 - _timestamp: 1652504170.0000 - _runtime: 383.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57e488e32e44f548a939b5bc6bcf26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.879 MB of 33.481 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.02624…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.62785</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.59761</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.71014</td></tr><tr><td>val_accuracy</td><td>0.66744</td></tr><tr><td>val_loss</td><td>0.59761</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">drawn-sweep-53</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/tohxipq2\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/tohxipq2</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_064947-tohxipq2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: p8hi74rx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_065622-p8hi74rx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/p8hi74rx\" target=\"_blank\">summer-sweep-54</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 37ms/step- loss: 1.9428 - accuracy: 0.58\n",
      "235/235 [==============================] - 612s 3s/step - loss: 1.9428 - accuracy: 0.5840 - val_loss: 0.6440 - val_accuracy: 0.6106 - _timestamp: 1652504806.0000 - _runtime: 624.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc2e772fc714b10aac10b0002de17c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.557 MB of 0.744 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.748414…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.58397</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.64399</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.94285</td></tr><tr><td>val_accuracy</td><td>0.61061</td></tr><tr><td>val_loss</td><td>0.64399</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">summer-sweep-54</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/p8hi74rx\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/p8hi74rx</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_065622-p8hi74rx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dz2yovmq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_070658-dz2yovmq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/dz2yovmq\" target=\"_blank\">misty-sweep-55</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 23ms/step- loss: 0.9557 - accuracy: 0.63\n",
      "469/469 [==============================] - 442s 942ms/step - loss: 0.9557 - accuracy: 0.6324 - val_loss: 0.6273 - val_accuracy: 0.6427 - _timestamp: 1652505273.0000 - _runtime: 454.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52b03ab32854d15a90fb2c17edc6cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.003 MB of 17.121 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.00015…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.63235</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.62725</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>0.95568</td></tr><tr><td>val_accuracy</td><td>0.64267</td></tr><tr><td>val_loss</td><td>0.62725</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">misty-sweep-55</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/dz2yovmq\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/dz2yovmq</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_070658-dz2yovmq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qautu4of with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_071452-qautu4of</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/qautu4of\" target=\"_blank\">pretty-sweep-56</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 24ms/step- loss: 1.1494 - accuracy: 0.51\n",
      "469/469 [==============================] - 492s 1s/step - loss: 1.1494 - accuracy: 0.5193 - val_loss: 0.6929 - val_accuracy: 0.5208 - _timestamp: 1652505796.0000 - _runtime: 504.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3fd42fa3d943159ea7ebe6b1a358c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.846 MB of 17.537 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.04823…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.51931</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.6929</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.14945</td></tr><tr><td>val_accuracy</td><td>0.52084</td></tr><tr><td>val_loss</td><td>0.6929</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pretty-sweep-56</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/qautu4of\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/qautu4of</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_071452-qautu4of\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 55e7his6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_072326-55e7his6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/55e7his6\" target=\"_blank\">radiant-sweep-57</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 28ms/step- loss: 3.1344 - accuracy: 0.57\n",
      "469/469 [==============================] - 635s 1s/step - loss: 3.1344 - accuracy: 0.5774 - val_loss: 0.6925 - val_accuracy: 0.6062 - _timestamp: 1652506454.0000 - _runtime: 648.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3cad54fc6e49289a4e6fdb7bd5fedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.742 MB of 0.839 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.884435…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5774</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.69253</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>3.13436</td></tr><tr><td>val_accuracy</td><td>0.60624</td></tr><tr><td>val_loss</td><td>0.69253</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">radiant-sweep-57</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/55e7his6\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/55e7his6</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_072326-55e7his6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 74vqlkrv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_073427-74vqlkrv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/74vqlkrv\" target=\"_blank\">crimson-sweep-58</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 19ms/step- loss: 3.1164 - accuracy: 0.62\n",
      "235/235 [==============================] - 433s 2s/step - loss: 3.1164 - accuracy: 0.6221 - val_loss: 0.6054 - val_accuracy: 0.6718 - _timestamp: 1652506912.0000 - _runtime: 444.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e68238664774f158b464addaa5e4fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.397 MB of 0.746 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.532308…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.62215</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.60545</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>3.11643</td></tr><tr><td>val_accuracy</td><td>0.67182</td></tr><tr><td>val_loss</td><td>0.60545</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">crimson-sweep-58</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/74vqlkrv\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/74vqlkrv</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_073427-74vqlkrv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1flw0f5h with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_074211-1flw0f5h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/1flw0f5h\" target=\"_blank\">genial-sweep-59</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 15ms/step- loss: 1.3364 - accuracy: 0.58\n",
      "469/469 [==============================] - 399s 844ms/step - loss: 1.3364 - accuracy: 0.5801 - val_loss: 0.6342 - val_accuracy: 0.6392 - _timestamp: 1652507344.0000 - _runtime: 413.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f806598080994b7db022c154d4675d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.836 MB of 0.836 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.58007</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.63418</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.33642</td></tr><tr><td>val_accuracy</td><td>0.63917</td></tr><tr><td>val_loss</td><td>0.63418</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">genial-sweep-59</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/1flw0f5h\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/1flw0f5h</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_074211-1flw0f5h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 67aorckb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_074925-67aorckb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/67aorckb\" target=\"_blank\">lilac-sweep-60</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 19ms/step- loss: 1.8354 - accuracy: 0.60\n",
      "235/235 [==============================] - 421s 2s/step - loss: 1.8354 - accuracy: 0.6007 - val_loss: 0.6006 - val_accuracy: 0.6817 - _timestamp: 1652507797.0000 - _runtime: 432.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ca032097824cd5953575f28fde895c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.538 MB of 0.781 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.688882…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.60074</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.60062</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.83536</td></tr><tr><td>val_accuracy</td><td>0.68173</td></tr><tr><td>val_loss</td><td>0.60062</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lilac-sweep-60</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/67aorckb\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/67aorckb</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_074925-67aorckb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ztt0sg48 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_075705-ztt0sg48</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/ztt0sg48\" target=\"_blank\">leafy-sweep-61</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 14ms/step- loss: 1.9144 - accuracy: 0.63\n",
      "469/469 [==============================] - 236s 502ms/step - loss: 1.9144 - accuracy: 0.6327 - val_loss: 0.5908 - val_accuracy: 0.6826 - _timestamp: 1652508073.0000 - _runtime: 248.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1042fad086149c3a6c913ae78252505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.799 MB of 17.031 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.04693…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.63272</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.59084</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.91436</td></tr><tr><td>val_accuracy</td><td>0.6826</td></tr><tr><td>val_loss</td><td>0.59084</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">leafy-sweep-61</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/ztt0sg48\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/ztt0sg48</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_075705-ztt0sg48\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o5xh7vj5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_080123-o5xh7vj5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/o5xh7vj5\" target=\"_blank\">firm-sweep-62</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 18ms/step- loss: 1.6333 - accuracy: 0.57\n",
      "469/469 [==============================] - 406s 859ms/step - loss: 1.6333 - accuracy: 0.5763 - val_loss: 0.9271 - val_accuracy: 0.5587 - _timestamp: 1652508502.0000 - _runtime: 419.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f37273fd06174a6fbc1927347b7ed86a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.204 MB of 0.799 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.255602…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5763</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.92713</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.63334</td></tr><tr><td>val_accuracy</td><td>0.55873</td></tr><tr><td>val_loss</td><td>0.92713</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">firm-sweep-62</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/o5xh7vj5\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/o5xh7vj5</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_080123-o5xh7vj5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q5kjl7dq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_080832-q5kjl7dq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/q5kjl7dq\" target=\"_blank\">solar-sweep-63</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 12ms/step- loss: 3.8462 - accuracy: 0.57\n",
      "118/118 [==============================] - 265s 2s/step - loss: 3.8462 - accuracy: 0.5702 - val_loss: 0.6036 - val_accuracy: 0.6774 - _timestamp: 1652508789.0000 - _runtime: 277.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a06286cd9d644ef8f2aebf4d00e0979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.802 MB of 33.175 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.02418…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.57023</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.60358</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>3.84618</td></tr><tr><td>val_accuracy</td><td>0.67735</td></tr><tr><td>val_loss</td><td>0.60358</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">solar-sweep-63</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/q5kjl7dq\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/q5kjl7dq</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_080832-q5kjl7dq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4q23lkj9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_081323-4q23lkj9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/4q23lkj9\" target=\"_blank\">breezy-sweep-64</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 15ms/step- loss: 1.6486 - accuracy: 0.57\n",
      "235/235 [==============================] - 256s 1s/step - loss: 1.6486 - accuracy: 0.5734 - val_loss: 0.7072 - val_accuracy: 0.5707 - _timestamp: 1652509070.0000 - _runtime: 267.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51015ca5fec340a8af91f6f40bc701e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.180 MB of 0.805 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.224240…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.5734</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.70717</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.64856</td></tr><tr><td>val_accuracy</td><td>0.57068</td></tr><tr><td>val_loss</td><td>0.70717</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">breezy-sweep-64</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/4q23lkj9\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/4q23lkj9</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_081323-4q23lkj9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6xm0qbd7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_081810-6xm0qbd7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/6xm0qbd7\" target=\"_blank\">classic-sweep-65</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 23ms/step- loss: 2.1932 - accuracy: 0.63\n",
      "469/469 [==============================] - 372s 792ms/step - loss: 2.1932 - accuracy: 0.6363 - val_loss: 0.6430 - val_accuracy: 0.6698 - _timestamp: 1652509473.0000 - _runtime: 383.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50591ededb9f4684bb222c70a7805105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='1.191 MB of 33.465 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.03557…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.63632</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.64302</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.19322</td></tr><tr><td>val_accuracy</td><td>0.66978</td></tr><tr><td>val_loss</td><td>0.64302</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">classic-sweep-65</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/6xm0qbd7\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/6xm0qbd7</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_081810-6xm0qbd7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zlgp2pbz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_082446-zlgp2pbz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/zlgp2pbz\" target=\"_blank\">decent-sweep-66</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "2/2 [==============================] - 0s 17ms/step- loss: 2.6025 - accuracy: 0.57\n",
      "235/235 [==============================] - 449s 2s/step - loss: 2.6025 - accuracy: 0.5720 - val_loss: 0.6449 - val_accuracy: 0.6284 - _timestamp: 1652509948.0000 - _runtime: 462.0000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9d526d038744248b20384a887b9862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.809 MB of 17.290 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.04677…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.57203</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>0.64493</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>2.6025</td></tr><tr><td>val_accuracy</td><td>0.62839</td></tr><tr><td>val_loss</td><td>0.64493</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">decent-sweep-66</strong>: <a href=\"https://wandb.ai/dat550/deepfake-basic/runs/zlgp2pbz\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/runs/zlgp2pbz</a><br/>Synced 5 W&B file(s), 37 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220514_082446-zlgp2pbz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: r5uj57s4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_1_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_2_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_3_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tuse_augmentation: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.16 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\henriks\\Documents\\skole\\master_linje\\2_semester\\DAT550\\prosjekt\\DAT550-project\\wandb\\run-20220514_083237-r5uj57s4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dat550/deepfake-basic/runs/r5uj57s4\" target=\"_blank\">likely-sweep-67</a></strong> to <a href=\"https://wandb.ai/dat550/deepfake-basic\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf\" target=\"_blank\">https://wandb.ai/dat550/deepfake-basic/sweeps/05mt6dlf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29988 files belonging to 2 classes.\n",
      "Found 3431 files belonging to 2 classes.\n",
      "Found 1587 files belonging to 2 classes.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause has no variant outputs and has no vectorized variant inputs\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause has no variant outputs and has no vectorized variant inputs\n",
      "372/469 [======================>.......] - ETA: 1:28 - loss: 1.6700 - accuracy: 0.5946"
     ]
    }
   ],
   "source": [
    "# sweep training\n",
    "sweep_config = {\n",
    "    \"name\": \"deepfake-basic-sweep\",\n",
    "   'method': 'bayes',\n",
    "    \"metric\": {\n",
    "            \"name\": \"accuracy\",\n",
    "            \"goal\": \"maximize\"\n",
    "        },\n",
    "    \"early_terminate\": {\n",
    "       \"type\": \"hyperband\",\n",
    "       \"min_iter\": 5\n",
    "   },\n",
    "   'parameters': {\n",
    "        'batch_size': {\n",
    "            'values': [64, 128, 256] \n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.0, 0.2, 0.5]\n",
    "        },\n",
    "        'conv_layer_1_size': {\n",
    "            'values': [16,32], #32\n",
    "        },\n",
    "        'conv_layer_2_size': {\n",
    "            'values': [32,64] #64\n",
    "        },\n",
    "        'conv_layer_3_size': {\n",
    "            'values': [64 ,128] # 128\n",
    "        },\n",
    "        'hidden_layer_size': {\n",
    "                'values': [64, 128] \n",
    "            },\n",
    "      'learning_rate': {\n",
    "            'values': [1e-2, 1e-3, 1e-4, 3e-4]\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'values': ['adam',  \"nadam\", 'sgd', 'rmsprop']\n",
    "        },\n",
    "          \"use_augmentation\": {\n",
    "            \"values\": [False, True] \n",
    "        }\n",
    "   }\n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project=wandb_project_name, entity=\"dat550\")\n",
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the bess model NB: edit namd and path\n",
    "loaded_model = wandb.restore('model-best.h5', run_path=\"dat550/deepfake-efficientnet/runs/29425ckm\")\n",
    "best_model = load_model(loaded_model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = ModelWrapper(data_dir, img_size, 32)\n",
    "model_wrapper.evaluate_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "model_wrapper.export_to_png()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6186f98b4107da167f8e04d2b53209365f80479d5668ca57b5633229f74e4af5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
